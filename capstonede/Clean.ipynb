{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import configparser\n",
    "import os\n",
    "from datetime import datetime,timedelta,date\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import col, sum, avg, max, monotonically_increasing_id\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, dayofweek, to_date\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "#from workspace_utils import active_session\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "#config.read('dl.cfg')\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]= 'AKIATP4ZOEIRHQKC67W5' #config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]= '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' #config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fca28254978>\n"
     ]
    }
   ],
   "source": [
    "# create spark session\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\")\\\n",
    "    .config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", os.environ[\"AWS_ACCESS_KEY_ID\"])\\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", os.environ[\"AWS_SECRET_ACCESS_KEY\"])\\\n",
    "    .enableHiveSupport().getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", os.environ['AWS_ACCESS_KEY_ID'])\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", os.environ['AWS_SECRET_ACCESS_KEY'])\n",
    "\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the immigration data here for June 2016\n",
    "#df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(cicid=6.0, i94yr=2016.0, i94mon=4.0, i94cit=692.0, i94res=692.0, i94port='XXX', arrdate=20573.0, i94mode=None, i94addr=None, depdate=None, i94bir=37.0, i94visa=2.0, count=1.0, dtadfile=None, visapost=None, occup=None, entdepa='T', entdepd=None, entdepu='U', matflag=None, biryear=1979.0, dtaddto='10282016', gender=None, insnum=None, airline=None, admnum=1897628485.0, fltno=None, visatype='B2')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_spark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder.\\\n",
    "# config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "# config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "# enableHiveSupport().getOrCreate()\n",
    "\n",
    "# df_spark_jan16 = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat')\n",
    "# df_spark_feb16 = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_feb16_sub.sas7bdat')\n",
    "# df_spark_mar16 = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_mar16_sub.sas7bdat')\n",
    "# df_spark_apr16 = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "# df_spark_may16 = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_may16_sub.sas7bdat')\n",
    "# df_spark_jun16 = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat')\n",
    "# df_spark_jul16 = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat')\n",
    "# df_spark_aug16 = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_aug16_sub.sas7bdat')\n",
    "# df_spark_sep16 = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_sep16_sub.sas7bdat')\n",
    "# df_spark_oct16 = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_oct16_sub.sas7bdat')\n",
    "# df_spark_nov16 = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_nov16_sub.sas7bdat')\n",
    "# df_spark_dec16 = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_dec16_sub.sas7bdat')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "# df_spark_jan16.write.mode(\"overwrite\").parquet(\"sas_parquet_data/jan2016/\")\n",
    "# df_spark_feb16.write.mode(\"overwrite\").parquet(\"sas_parquet_data/feb2016/\")\n",
    "# df_spark_mar16.write.mode(\"overwrite\").parquet(\"sas_parquet_data/mar2016/\")\n",
    "# df_spark_apr16.write.mode(\"overwrite\").parquet(\"sas_parquet_data/apr2016/\")\n",
    "# df_spark_may16.write.mode(\"overwrite\").parquet(\"sas_parquet_data/may2016/\")\n",
    "# df_spark_jun16.write.mode(\"overwrite\").parquet(\"sas_parquet_data/jun2016/\")\n",
    "# df_spark_jul16.write.mode(\"overwrite\").parquet(\"sas_parquet_data/jul2016/\")\n",
    "# df_spark_aug16.write.mode(\"overwrite\").parquet(\"sas_parquet_data/aug2016/\")\n",
    "# df_spark_sep16.write.mode(\"overwrite\").parquet(\"sas_parquet_data/sep2016/\")\n",
    "# df_spark_oct16.write.mode(\"overwrite\").parquet(\"sas_parquet_data/oct2016/\")\n",
    "# df_spark_nov16.write.mode(\"overwrite\").parquet(\"sas_parquet_data/nov2016/\")\n",
    "# df_spark_dec16.write.mode(\"overwrite\").parquet(\"sas_parquet_data/dec2016/\")\n",
    "\n",
    "#df_spark.write.mode(\"overwrite\").parquet(\"sridhar_parque\")\n",
    "#df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Now read data from all 2016 files and prepare staging immigration data\n",
    "#only jan data : 2847924\n",
    "#only feb data : 2570543\n",
    "# Read in the immigration data here for June 2016\n",
    "df_staging_immigration_data = spark.read.parquet('sas_parquet_data/apr2016/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_staging_immigration_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+------------+--------------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|arrival_date|departure_date|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+------------+--------------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD|   NA|      G|      O|     NA|      M| 1976.0|10292016|     F|    NA|     QF|9.495387003E10|00011|      B1|  2016-04-30|    2016-05-08|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD|   NA|      G|      O|     NA|      M| 1984.0|10292016|     F|    NA|     VA|9.495562283E10|00007|      B1|  2016-04-30|    2016-05-17|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD|   NA|      G|      O|     NA|      M| 1987.0|10292016|     M|    NA|     DL|9.495640653E10|00040|      B1|  2016-04-30|    2016-05-08|\n",
      "|5748520.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  29.0|    1.0|  1.0|20160430|     SYD|   NA|      G|      O|     NA|      M| 1987.0|10292016|     F|    NA|     DL|9.495645143E10|00040|      B1|  2016-04-30|    2016-05-14|\n",
      "|5748521.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  28.0|    1.0|  1.0|20160430|     SYD|   NA|      G|      O|     NA|      M| 1988.0|10292016|     M|    NA|     DL|9.495638813E10|00040|      B1|  2016-04-30|    2016-05-14|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_staging_immigration_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#SAS file section I94ADDR contains state code\n",
    "df_staging_I94_state_code = spark.read.option(\"header\",True).options(delimiter=',').csv(\"datafiles/I94_state_code_name.csv\")\n",
    "\n",
    "#SAS file section I94CIT_I94RES contains country code and country name info\n",
    "df_staging_I94_country_code = spark.read.option(\"header\",True).options(delimiter=',').csv(\"datafiles/I94_country_code_name.csv\")\n",
    "\n",
    "#SAS file section I94MODE contains  I94 mode type info\n",
    "df_staging_I94_mode = spark.read.option(\"header\",True).options(delimiter=',').csv(\"datafiles/I94_mode.csv\")\n",
    "\n",
    "#SAS file section I94PORT contains port and city info\n",
    "df_staging_I94_port_city = spark.read.option(\"header\",True).options(delimiter=',').csv(\"datafiles/I94_port_city.csv\")\n",
    "\n",
    "#SAS file section I94VISA contains visa type info\n",
    "df_staging_I94_visa_type = spark.read.option(\"header\",True).options(delimiter=',').csv(\"datafiles/I94_visa_type.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#capture row counts for staging dataframes\n",
    "rowcount_immigration_data = df_staging_immigration_data.count()\n",
    "rowcount_I94_state_code = df_staging_I94_state_code.count()\n",
    "rowcount_I94_country_code = df_staging_I94_country_code.count()\n",
    "rowcount_I94_mode= df_staging_I94_mode.count()\n",
    "rowcount_I94_port_city = df_staging_I94_port_city.count()\n",
    "rowcount_I94_visa_type = df_staging_I94_visa_type.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|state_code|state_name|\n",
      "+----------+----------+\n",
      "|        AL|   ALABAMA|\n",
      "|        AK|    ALASKA|\n",
      "|        AZ|   ARIZONA|\n",
      "|        AR|  ARKANSAS|\n",
      "|        CA|CALIFORNIA|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------+--------------+\n",
      "|country_code|  country_name|\n",
      "+------------+--------------+\n",
      "|         582|MEXICO Air Sea|\n",
      "|         236|   AFGHANISTAN|\n",
      "|         101|       ALBANIA|\n",
      "|         316|       ALGERIA|\n",
      "|         102|       ANDORRA|\n",
      "+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+------------+\n",
      "|mode_id|   mode_name|\n",
      "+-------+------------+\n",
      "|      1|         Air|\n",
      "|      2|         Sea|\n",
      "|      3|        Land|\n",
      "|      9|Not reported|\n",
      "+-------+------------+\n",
      "\n",
      "+---------+--------------------+----------+\n",
      "|city_code|       city_province|state_code|\n",
      "+---------+--------------------+----------+\n",
      "|      ALC|               ALCAN|       AK |\n",
      "|      ANC|           ANCHORAGE|        AK|\n",
      "|      BAR|BAKER AAF - BAKER...|        AK|\n",
      "|      DAC|       DALTONS CACHE|      AK  |\n",
      "|      PIZ|DEW STATION PT LA...|        AK|\n",
      "+---------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------+---------+\n",
      "|visa_type_id|visa_type|\n",
      "+------------+---------+\n",
      "|           1| Business|\n",
      "|           2| Pleasure|\n",
      "|           3|  Student|\n",
      "+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_staging_I94_state_code.show(5)\n",
    "df_staging_I94_country_code.show(5)\n",
    "df_staging_I94_mode.show(5)\n",
    "df_staging_I94_port_city.show(5)\n",
    "df_staging_I94_visa_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#load airport codes data\n",
    "df_staging_airport_codes = spark.read.option(\"header\",True).options(delimiter=\",\").csv(\"datafiles/airport-codes_csv.csv\")\n",
    "#rowcount_airport_codes = df_staging_airport_codes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#load iata airport codes and join with df_staging_airport_codes\n",
    "df_staging_iata_codes = spark.read.option(\"header\",True).options(delimiter=\",\").csv(\"datafiles/US_iata_codes.csv\")\n",
    "#df_staging_iata_codes.printSchema()\n",
    "#rowcount_iata_codes = df_staging_iata_codes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#load US city demographics\n",
    "staging_us_cities_demographics= spark.read.option(\"header\",True).options(delimiter=\";\").csv(\"datafiles/us-cities-demographics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create function to convert double to datetime value\n",
    "def convert_double_to_datetime(x):\n",
    "    try:\n",
    "        if x == 'null':\n",
    "            x = 0\n",
    "        start = datetime(1960, 1, 1)\n",
    "        return start + timedelta(days=int(x))\n",
    "    except:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create udf to update arrival and departure date columns\n",
    "udf_datetime = udf(lambda x: convert_double_to_datetime(x), T.DateType())\n",
    "df_staging_immigration_data = df_staging_immigration_data.withColumn('arrival_date',udf_datetime(df_staging_immigration_data.arrdate))\n",
    "df_staging_immigration_data = df_staging_immigration_data.withColumn('departure_date',udf_datetime(df_staging_immigration_data.depdate))\n",
    "df_staging_immigration_data = df_staging_immigration_data.fillna({\\\n",
    "         'i94yr':      0.0,\\\n",
    "         'i94addr':   'NA',\\\n",
    "         'arrdate':   'NA',\\\n",
    "         'depdate':   'NA',\\\n",
    "         'i94bir':    'NA',\\\n",
    "         'i94visa':    0.0,\\\n",
    "         'count':      0.0,\\\n",
    "         'dtadfile':  'NA',\\\n",
    "         'visapost':  'NA',\\\n",
    "         'occup':     'NA',\\\n",
    "         'entdepa':   'NA',\\\n",
    "         'entdepd':   'NA',\\\n",
    "         'entdepu':   'NA',\\\n",
    "         'matflag':   'NA',\\\n",
    "         'biryear':   'NA',\\\n",
    "         'dtaddto':   'NA',\\\n",
    "         'gender':    'NA',\\\n",
    "         'insnum':    'NA',\\\n",
    "         'airline':   'NA',\\\n",
    "         'admnum':     0.0,\\\n",
    "         'fltno':     'NA',\\\n",
    "         'visatype':  'NA'\\\n",
    "         })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_staging_immigration_data = df_staging_immigration_data.filter((col(\"arrdate\") == 'NA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+-------+------+------+-------+------+-----+--------+------------+--------------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender|insnum|airline|admnum|fltno|visatype|arrival_date|departure_date|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+-------+------+------+-------+------+-----+--------+------------+--------------+\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+-------+------+------+-------+------+-----+--------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_staging_immigration_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>country_of_origin</th>\n",
       "      <th>i94port</th>\n",
       "      <th>i94port_city</th>\n",
       "      <th>i94port_statecode</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>state_code</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>age</th>\n",
       "      <th>visatype</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>fltno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [cicid, i94yr, i94mon, i94addr, country_of_origin, i94port, i94port_city, i94port_statecode, arrival_date, month, year, i94mode, state_code, departure_date, age, visatype, i94visa, birth_year, gender, airline, fltno]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_staging_immigration_data.createOrReplaceTempView(\"tbl_stg_immigration_data\")\n",
    "df_staging_I94_state_code.createOrReplaceTempView(\"tbl_I94ADDR_Mapping\")\n",
    "df_staging_I94_country_code.createOrReplaceTempView(\"tbl_I94CIT_I94RES_Mapping\")\n",
    "df_staging_I94_mode.createOrReplaceTempView(\"tbl_I94MODE_Mapping\")\n",
    "df_staging_I94_port_city.createOrReplaceTempView(\"tbl_I94PORT_Mapping\")\n",
    "df_staging_I94_visa_type.createOrReplaceTempView(\"tbl_I94VISA_Mapping\")\n",
    "df_final_immigration = spark.sql(\"\"\"\n",
    "\n",
    "            SELECT DISTINCT IMM.cicid\n",
    "                           ,IMM.i94yr\n",
    "                           ,IMM.i94mon\n",
    "                           ,IMM.i94addr\n",
    "                           ,I94CIT_I94RES1.country_name as country_of_origin\n",
    "                           ,trim(IMM.i94port) as i94port\n",
    "                           ,initcap(lower(trim(SPLIT(I94PORT.city_province,',')[0]))) as i94port_city\n",
    "                           ,I94PORT.state_code as i94port_statecode\n",
    "                           ,arrival_date\n",
    "                           ,month(arrival_date) as month\n",
    "                           ,year(arrival_date) as year\n",
    "                           ,I94MODE.mode_name  as i94mode\n",
    "                           ,i94addr as state_code\n",
    "                           ,departure_date\n",
    "                           ,i94bir as age\n",
    "                           ,IMM.visatype \n",
    "                           ,I94VISA.visa_type as i94visa\n",
    "                           ,biryear as birth_year\n",
    "                           ,gender\n",
    "                           ,airline\n",
    "                           ,fltno   \n",
    "            FROM tbl_stg_immigration_data AS IMM \n",
    "            LEFT JOIN tbl_I94ADDR_Mapping AS I94ADDR on IMM.i94addr = I94ADDR.state_code \n",
    "            LEFT JOIN tbl_I94CIT_I94RES_Mapping AS I94CIT_I94RES1 on IMM.i94cit = I94CIT_I94RES1.country_code\n",
    "            LEFT JOIN tbl_I94MODE_Mapping AS I94MODE on IMM.i94mode = I94MODE.mode_name \n",
    "            LEFT JOIN tbl_I94PORT_Mapping AS I94PORT on IMM.i94port = I94PORT.city_code \n",
    "            LEFT JOIN tbl_I94VISA_Mapping AS I94VISA on IMM.visatype = I94VISA.visa_type\n",
    "            WHERE arrival_date IS NOT NULL AND IMM.arrdate !='NA'\n",
    "            \"\"\")\n",
    "df_final_immigration.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_final_immigration.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2943627"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_immigration.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_immigration.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#drop rows with iata_code as null\n",
    "df_staging_airport_codes.dropna(subset=[\"iata_code\"])\n",
    "#check iata_code in airport_codes data and drop invalid entries\n",
    "df_staging_airport_codes= df_staging_airport_codes.filter(df_staging_airport_codes['iata_code'].rlike('^[A-Z]'))\n",
    "df_staging_airport_codes.dropna()\n",
    "#filter airport_codes data for US airports\n",
    "df_final_airport_codes = df_staging_airport_codes.filter((col(\"iata_code\") != 'USA') & (col(\"iso_country\") == 'US'))\n",
    "\n",
    "df_final_airport_codes.printSchema()\n",
    "rowcount_airport_codes = df_final_airport_codes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>airport_name</th>\n",
       "      <th>airport_type</th>\n",
       "      <th>airport_identity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>AUS</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>None</td>\n",
       "      <td>KAUS</td>\n",
       "      <td>None</td>\n",
       "      <td>-97.6997852325, 30.2987223546</td>\n",
       "      <td>Austin Robert Mueller Municipal</td>\n",
       "      <td>closed</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Craig</td>\n",
       "      <td>AK</td>\n",
       "      <td>CGA</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Craig</td>\n",
       "      <td>CGA</td>\n",
       "      <td>CGA</td>\n",
       "      <td>-133.1479949951172, 55.47880172729492</td>\n",
       "      <td>Craig Seaplane Base</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>CGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allentown</td>\n",
       "      <td>PA</td>\n",
       "      <td>ABE</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Allentown</td>\n",
       "      <td>KABE</td>\n",
       "      <td>ABE</td>\n",
       "      <td>-75.44080352783203, 40.652099609375</td>\n",
       "      <td>Lehigh Valley International Airport</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>KABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>ABI</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>KABI</td>\n",
       "      <td>ABI</td>\n",
       "      <td>-99.68190002440001, 32.4113006592</td>\n",
       "      <td>Abilene Regional Airport</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>KABI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NM</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>KABQ</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>-106.609001, 35.040199</td>\n",
       "      <td>Albuquerque International Sunport</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>KABQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>SD</td>\n",
       "      <td>ABR</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-SD</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>KABR</td>\n",
       "      <td>ABR</td>\n",
       "      <td>-98.42179870605469, 45.449100494384766</td>\n",
       "      <td>Aberdeen Regional Airport</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>KABR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "      <td>ABY</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-GA</td>\n",
       "      <td>Albany</td>\n",
       "      <td>KABY</td>\n",
       "      <td>ABY</td>\n",
       "      <td>-84.19450378417969, 31.535499572753906</td>\n",
       "      <td>Southwest Georgia Regional Airport</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>KABY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nantucket</td>\n",
       "      <td>MA</td>\n",
       "      <td>ACK</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MA</td>\n",
       "      <td>Nantucket</td>\n",
       "      <td>KACK</td>\n",
       "      <td>ACK</td>\n",
       "      <td>-70.06020355, 41.25310135</td>\n",
       "      <td>Nantucket Memorial Airport</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>KACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Waco</td>\n",
       "      <td>TX</td>\n",
       "      <td>ACT</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Waco</td>\n",
       "      <td>KACT</td>\n",
       "      <td>ACT</td>\n",
       "      <td>-97.23049926757812, 31.611299514770508</td>\n",
       "      <td>Waco Regional Airport</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>KACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Eureka</td>\n",
       "      <td>CA</td>\n",
       "      <td>ACV</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Arcata/Eureka</td>\n",
       "      <td>KACV</td>\n",
       "      <td>ACV</td>\n",
       "      <td>-124.109, 40.978101</td>\n",
       "      <td>California Redwood Coast-Humboldt County Airport</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>KACV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city state_code iata_code continent iso_country iso_region  \\\n",
       "0       Austin         TX       AUS        NA          US      US-TX   \n",
       "1        Craig         AK       CGA        NA          US      US-AK   \n",
       "2    Allentown         PA       ABE        NA          US      US-PA   \n",
       "3      Abilene         TX       ABI        NA          US      US-TX   \n",
       "4  Albuquerque         NM       ABQ        NA          US      US-NM   \n",
       "5     Aberdeen         SD       ABR        NA          US      US-SD   \n",
       "6       Albany         GA       ABY        NA          US      US-GA   \n",
       "7    Nantucket         MA       ACK        NA          US      US-MA   \n",
       "8         Waco         TX       ACT        NA          US      US-TX   \n",
       "9       Eureka         CA       ACV        NA          US      US-CA   \n",
       "\n",
       "    municipality gps_code local_code                             coordinates  \\\n",
       "0           None     KAUS       None           -97.6997852325, 30.2987223546   \n",
       "1          Craig      CGA        CGA   -133.1479949951172, 55.47880172729492   \n",
       "2      Allentown     KABE        ABE     -75.44080352783203, 40.652099609375   \n",
       "3        Abilene     KABI        ABI       -99.68190002440001, 32.4113006592   \n",
       "4    Albuquerque     KABQ        ABQ                  -106.609001, 35.040199   \n",
       "5       Aberdeen     KABR        ABR  -98.42179870605469, 45.449100494384766   \n",
       "6         Albany     KABY        ABY  -84.19450378417969, 31.535499572753906   \n",
       "7      Nantucket     KACK        ACK               -70.06020355, 41.25310135   \n",
       "8           Waco     KACT        ACT  -97.23049926757812, 31.611299514770508   \n",
       "9  Arcata/Eureka     KACV        ACV                     -124.109, 40.978101   \n",
       "\n",
       "                                       airport_name    airport_type  \\\n",
       "0                   Austin Robert Mueller Municipal          closed   \n",
       "1                               Craig Seaplane Base   seaplane_base   \n",
       "2               Lehigh Valley International Airport  medium_airport   \n",
       "3                          Abilene Regional Airport  medium_airport   \n",
       "4                 Albuquerque International Sunport   large_airport   \n",
       "5                         Aberdeen Regional Airport  medium_airport   \n",
       "6                Southwest Georgia Regional Airport  medium_airport   \n",
       "7                        Nantucket Memorial Airport  medium_airport   \n",
       "8                             Waco Regional Airport  medium_airport   \n",
       "9  California Redwood Coast-Humboldt County Airport  medium_airport   \n",
       "\n",
       "  airport_identity  \n",
       "0              AUS  \n",
       "1              CGA  \n",
       "2             KABE  \n",
       "3             KABI  \n",
       "4             KABQ  \n",
       "5             KABR  \n",
       "6             KABY  \n",
       "7             KACK  \n",
       "8             KACT  \n",
       "9             KACV  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare clean airport codes\n",
    "df_final_airport_codes.createOrReplaceTempView(\"tbl_stg_airport_codes\")\n",
    "df_staging_iata_codes.createOrReplaceTempView(\"tbl_stg_iata_codes\")\n",
    "df_final_city_airport_info = spark.sql(\"\"\"\n",
    "                                    SELECT ia.City as city,\n",
    "                                           ia.State as state_code,\n",
    "                                           ia.Code as iata_code,\n",
    "                                           ap.continent AS continent,\n",
    "                                           ap.iso_country AS iso_country,\n",
    "                                           ap.iso_region AS iso_region,\n",
    "                                           ap.municipality,\n",
    "                                           ap.gps_code,                                           \n",
    "                                           ap.local_code,\n",
    "                                           ap.coordinates,\n",
    "                                           ap.name AS airport_name,\n",
    "                                           ap.type AS airport_type,\n",
    "                                           ap.ident AS airport_identity\n",
    "                                    FROM tbl_stg_airport_codes ap\n",
    "                                    JOIN tbl_stg_iata_codes ia\n",
    "                                      ON  ap.iata_code=ia.Code\n",
    "                                    WHERE ap.continent = 'NA'\n",
    "                                     AND ap.iso_country = 'US'\n",
    "                                    \"\"\")\n",
    "\n",
    "df_final_city_airport_info.count()\n",
    "df_final_city_airport_info.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#clean the data for us city demographics\n",
    "df_staging_us_cities_demographics = df_staging_us_cities_demographics.filter(df_staging_us_cities_demographics.City.isNotNull())\n",
    "df_staging_us_cities_demographics=df_staging_us_cities_demographics.dropna()\n",
    "\n",
    "df_staging_us_cities_demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_value: date (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create time dimension table\n",
    "df_time = spark.sql(\"\"\"\n",
    "                    SELECT DISTINCT arrival_date AS date_value FROM tbl_stg_immigration_data WHERE arrival_date IS NOT NULL \n",
    "                    UNION \n",
    "                    SELECT DISTINCT departure_date AS date_value FROM tbl_stg_immigration_data WHERE departure_date IS NOT NULL \n",
    "                    \"\"\")\n",
    "df_time = df_time.withColumn('day',dayofmonth(df_time.date_value)) \\\n",
    "    .withColumn('week',weekofyear(df_time.date_value)) \\\n",
    "    .withColumn('month',month(df_time.date_value)) \\\n",
    "    .withColumn('year',year(df_time.date_value)) \\\n",
    "    .withColumn('weekday',dayofweek(df_time.date_value)) \n",
    "#df_time_clean.limit(10).toPandas()\n",
    "\n",
    "df_time.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>race</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>escondido</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>33.3</td>\n",
       "      <td>76551</td>\n",
       "      <td>74907</td>\n",
       "      <td>151458</td>\n",
       "      <td>8110</td>\n",
       "      <td>46298</td>\n",
       "      <td>3.27</td>\n",
       "      <td>CA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>3151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rockford</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>36.3</td>\n",
       "      <td>71076</td>\n",
       "      <td>78270</td>\n",
       "      <td>149346</td>\n",
       "      <td>8894</td>\n",
       "      <td>18323</td>\n",
       "      <td>2.52</td>\n",
       "      <td>IL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yuba city</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>34.5</td>\n",
       "      <td>33654</td>\n",
       "      <td>33290</td>\n",
       "      <td>66944</td>\n",
       "      <td>4706</td>\n",
       "      <td>18032</td>\n",
       "      <td>2.9</td>\n",
       "      <td>CA</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>20890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        city       state median_age male_population female_population  \\\n",
       "0  escondido  CALIFORNIA       33.3           76551             74907   \n",
       "1   rockford    ILLINOIS       36.3           71076             78270   \n",
       "2  yuba city  CALIFORNIA       34.5           33654             33290   \n",
       "\n",
       "  total_population number_of_veterans foreign_born average_household_size  \\\n",
       "0           151458               8110        46298                   3.27   \n",
       "1           149346               8894        18323                   2.52   \n",
       "2            66944               4706        18032                    2.9   \n",
       "\n",
       "  state_code                               race  count  \n",
       "0         CA  American Indian and Alaska Native   3151  \n",
       "1         IL                              Asian   5500  \n",
       "2         CA                 Hispanic or Latino  20890  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_staging_us_cities_demographics.createOrReplaceTempView(\"tbl_stg_us_cities_demographics\")\n",
    "df_final_us_city_demographics = spark.sql(\"\"\"\n",
    "                                            SELECT DISTINCT LOWER(City) as city, \n",
    "                                                UPPER(State) as state, \n",
    "                                                `Median Age` AS median_age, \n",
    "                                                `Male Population` AS male_population, \n",
    "                                                `Female Population` AS female_population, \n",
    "                                                `Total Population` AS total_population, \n",
    "                                                `Number of Veterans` AS number_of_veterans, \n",
    "                                                `Foreign-born` AS foreign_born, \n",
    "                                                `Average Household Size` AS average_household_size, \n",
    "                                                rtrim(ltrim(`State Code`)) AS state_code, \n",
    "                                                race, \n",
    "                                                count\n",
    "                                            FROM tbl_stg_us_cities_demographics                  \n",
    "                                            \"\"\")\n",
    "df_final_us_city_demographics.limit(3).toPandas()\n",
    "#df_final_us_city_demographics.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+-----------------+------------------+------------+-------------+------------+-----------------+------+----------+---------------------------+----------------------+\n",
      "|  cicid|country_of_origin|arrival_airport_code|arrival_city_name|arrival_state_code|arrival_date|arrival_month|arrival_year|arrival_visa_type|gender|birth_year|destination_city_population|destination_median_age|\n",
      "+-------+-----------------+--------------------+-----------------+------------------+------------+-------------+------------+-----------------+------+----------+---------------------------+----------------------+\n",
      "|3261635|   MEXICO Air Sea|                 LRD|           Laredo|                TX|  2016-12-16|           12|        2016|               B1|     M|      1982|                     255789|                  28.8|\n",
      "|1762900|   MEXICO Air Sea|                 LRD|           Laredo|                TX|  2016-12-09|           12|        2016|               B2|     F|      1970|                     255789|                  28.8|\n",
      "|1370319|   MEXICO Air Sea|                 LRD|           Laredo|                TX|  2016-12-07|           12|        2016|               B1|     M|      1965|                     255789|                  28.8|\n",
      "|4373028|   MEXICO Air Sea|                 LRD|           Laredo|                TX|  2016-12-21|           12|        2016|               B1|     M|      1972|                     255789|                  28.8|\n",
      "|3559394|            SPAIN|                 LRD|           Laredo|                TX|  2016-12-17|           12|        2016|               WT|     M|      1971|                     255789|                  28.8|\n",
      "+-------+-----------------+--------------------+-----------------+------------------+------------+-------------+------------+-----------------+------+----------+---------------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write code here\n",
    "df_final_immigration.createOrReplaceTempView(\"tbl_immigration_data\")\n",
    "df_final_city_airport_info.createOrReplaceTempView(\"tbl_city_airport_info\")\n",
    "df_final_us_city_demographics.createOrReplaceTempView(\"tbl_us_city_demographics\")\n",
    "df_time.createOrReplaceTempView(\"tbl_time\")\n",
    "df_immigration_by_city = spark.sql(\"\"\"SELECT \n",
    "                                            CAST(imm.cicid AS int) AS cicid,\n",
    "                                            imm.country_of_origin,\n",
    "                                            cai.iata_code AS arrival_airport_code,\n",
    "                                            cai.city AS arrival_city_name,\n",
    "                                            cai.state_code AS arrival_state_code,\n",
    "                                            imm.arrival_date,  \n",
    "                                            dt.month AS arrival_month,\n",
    "                                            dt.year AS arrival_year,\n",
    "                                            imm.visatype AS arrival_visa_type,             \n",
    "                                            imm.gender,   \n",
    "                                            CAST(imm.birth_year AS int) AS birth_year,\n",
    "                                            cdem.total_population AS destination_city_population,\n",
    "                                            cdem.median_age AS destination_median_age\n",
    "                                     FROM tbl_immigration_data imm\n",
    "                                     JOIN tbl_us_city_demographics cdem\n",
    "                                       ON imm.i94port_statecode = cdem.state_code\n",
    "                                      AND LOWER(imm.i94port_city) = LOWER(cdem.city)\n",
    "                                     JOIN tbl_city_airport_info cai\n",
    "                                       ON LOWER(cdem.city) = LOWER(cai.city)\n",
    "                                      AND trim(cdem.state_code) = trim(cai.state_code)\n",
    "                                     JOIN tbl_time dt\n",
    "                                       ON imm.arrival_date = dt.date_value\n",
    "                                 \"\"\").dropDuplicates()\n",
    "df_immigration_by_city.dropna()\n",
    "\n",
    "df_immigration_by_city.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|invalid_cicid|\n",
      "+-------------+\n",
      "|            0|\n",
      "+-------------+\n",
      "\n",
      "+---------------------+\n",
      "|invalid_airport_codes|\n",
      "+---------------------+\n",
      "|                    0|\n",
      "+---------------------+\n",
      "\n",
      "+--------------+\n",
      "|invalid_cities|\n",
      "+--------------+\n",
      "|             0|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "# Performing cleaning tasks here\n",
    "df_final_immigration.createOrReplaceTempView(\"staging_immigration\")\n",
    "cicid_count_check = spark.sql(\"\"\"SELECT COUNT(*) AS invalid_cicid FROM staging_immigration WHERE cicid IS  NULL\"\"\")\n",
    "cicid_count_check.show()\n",
    "\n",
    "df_final_city_airport_info.createOrReplaceTempView(\"airport_codes_final\")\n",
    "airport_codes_check= spark.sql(\"\"\"SELECT COUNT(*) AS invalid_airport_codes FROM airport_codes_final WHERE iata_code IS NULL\"\"\")\n",
    "airport_codes_check.show(1)\n",
    "\n",
    "df_final_us_city_demographics.createOrReplaceTempView(\"us_cities_demo_final\")\n",
    "us_cities_demo_check= spark.sql(\"\"\"SELECT COUNT(*) AS invalid_cities FROM us_cities_demo_final WHERE City IS NULL\"\"\")\n",
    "us_cities_demo_check.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = false)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- country_of_origin: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- i94port_city: string (nullable = true)\n",
      " |-- i94port_statecode: string (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- i94mode: string (nullable = true)\n",
      " |-- state_code: string (nullable = false)\n",
      " |-- departure_date: date (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- visatype: string (nullable = false)\n",
      " |-- i94visa: string (nullable = true)\n",
      " |-- birth_year: double (nullable = true)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- airline: string (nullable = false)\n",
      " |-- fltno: string (nullable = false)\n",
      "\n",
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      " |-- airport_name: string (nullable = true)\n",
      " |-- airport_type: string (nullable = true)\n",
      " |-- airport_identity: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: string (nullable = true)\n",
      " |-- male_population: string (nullable = true)\n",
      " |-- female_population: string (nullable = true)\n",
      " |-- total_population: string (nullable = true)\n",
      " |-- number_of_veterans: string (nullable = true)\n",
      " |-- foreign_born: string (nullable = true)\n",
      " |-- average_household_size: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- date_value: date (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- country_of_origin: string (nullable = true)\n",
      " |-- arrival_airport_code: string (nullable = true)\n",
      " |-- arrival_city_name: string (nullable = true)\n",
      " |-- arrival_state_code: string (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- arrival_month: integer (nullable = true)\n",
      " |-- arrival_year: integer (nullable = true)\n",
      " |-- arrival_visa_type: string (nullable = false)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- destination_city_population: string (nullable = true)\n",
      " |-- destination_median_age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final_immigration.printSchema()\n",
    "df_final_city_airport_info.printSchema()\n",
    "df_final_us_city_demographics.printSchema()\n",
    "df_time.printSchema()\n",
    "df_immigration_by_city.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------+\n",
      "|arrival_airport_code|arrival_month|no_of_arrivals|\n",
      "+--------------------+-------------+--------------+\n",
      "|                 LAS|           12|         57370|\n",
      "|                 JAX|           12|            22|\n",
      "|                 CAK|           12|             1|\n",
      "|                 ANC|           12|           133|\n",
      "|                 MLB|           12|            77|\n",
      "|                 AUS|           12|          3402|\n",
      "|                 LGB|           12|           427|\n",
      "|                 LRD|           12|           581|\n",
      "|                 CLT|           12|         15208|\n",
      "|                 BNA|           12|           290|\n",
      "|                 PBI|           12|          3560|\n",
      "|                 GRB|           12|             8|\n",
      "|                 BHM|           12|             4|\n",
      "|                 FAT|           12|            21|\n",
      "|                 DSM|           12|             3|\n",
      "|                 ONT|           12|          2041|\n",
      "|                 ROC|           12|            70|\n",
      "|                 MKE|           12|            80|\n",
      "|                 RST|           12|            30|\n",
      "|                 IND|           12|           191|\n",
      "+--------------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-------------+--------------+\n",
      "|   country_of_origin|arrival_month|no_of_arrivals|\n",
      "+--------------------+-------------+--------------+\n",
      "|          BANGLADESH|           12|            30|\n",
      "|              PANAMA|           12|           492|\n",
      "|ST. VINCENT-GRENA...|           12|             5|\n",
      "|            PARAGUAY|           12|            33|\n",
      "|           ST. LUCIA|           12|            40|\n",
      "|            ZIMBABWE|           12|            21|\n",
      "|             ERITREA|           12|             3|\n",
      "|             ARMENIA|           12|             3|\n",
      "|        BURKINA FASO|           12|             4|\n",
      "|             BURUNDI|           12|             2|\n",
      "|              MONACO|           12|            15|\n",
      "|               EGYPT|           12|            73|\n",
      "|            COLOMBIA|           12|          1304|\n",
      "|           SRI LANKA|           12|            25|\n",
      "|           MACEDONIA|           12|             5|\n",
      "|              CYPRUS|           12|            40|\n",
      "|             BERMUDA|           12|             5|\n",
      "|             NIGERIA|           12|           122|\n",
      "|           MAURITIUS|           12|            20|\n",
      "|             ALBANIA|           12|            12|\n",
      "+--------------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample Analytic Queries\n",
    "\n",
    "df_immigration_by_city.createOrReplaceTempView(\"tbl_immigration_by_city\")\n",
    "\n",
    "#by airport,by month\n",
    "df_immigration_by_airport = spark.sql(\"\"\"SELECT arrival_airport_code, arrival_month, count(*) as no_of_arrivals\n",
    "                                      FROM tbl_immigration_by_city\n",
    "                                      GROUP BY arrival_airport_code, arrival_month\"\"\")\n",
    "df_immigration_by_airport.show()\n",
    "\n",
    "#by country_of_origin,month\n",
    "df_immigration_by_country_of_origin = spark.sql(\"\"\"SELECT country_of_origin, arrival_month, count(*) as no_of_arrivals\n",
    "                                      FROM tbl_immigration_by_city\n",
    "                                      GROUP BY country_of_origin, arrival_month\"\"\")\n",
    "df_immigration_by_country_of_origin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
